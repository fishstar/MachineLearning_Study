{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning in Python(4) - Fine-tuning keras models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding model optimization\n",
    "\n",
    "### Changing optimization parameters\n",
    "\n",
    "It's time to get your hands dirty with optimization. You'll now try optimizing a model at a very low learning rate, a very high learning rate, and a \"just right\" learning rate. You'll want to look at the results after running this exercise, remembering that a low value for the loss function is good.\n",
    "\n",
    "For these exercises, we've pre-loaded the predictors and target values from your previous classification models (predicting who would survive on the Titanic). You'll want the optimization to start from scratch every time you change the learning rate, to give a fair comparison of how each learning rate did in your results. So we have created a function get_new_model() that creates an unoptimized model to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>male</th>\n",
       "      <th>age_was_missing</th>\n",
       "      <th>embarked_from_cherbourg</th>\n",
       "      <th>embarked_from_queenstown</th>\n",
       "      <th>embarked_from_southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass   age  sibsp  parch     fare  male  age_was_missing  \\\n",
       "0         0       3  22.0      1      0   7.2500     1            False   \n",
       "1         1       1  38.0      1      0  71.2833     0            False   \n",
       "2         1       3  26.0      0      0   7.9250     0            False   \n",
       "3         1       1  35.0      1      0  53.1000     0            False   \n",
       "4         0       3  35.0      0      0   8.0500     1            False   \n",
       "\n",
       "   embarked_from_cherbourg  embarked_from_queenstown  \\\n",
       "0                        0                         0   \n",
       "1                        1                         0   \n",
       "2                        0                         0   \n",
       "3                        0                         0   \n",
       "4                        0                         0   \n",
       "\n",
       "   embarked_from_southampton  \n",
       "0                          1  \n",
       "1                          0  \n",
       "2                          1  \n",
       "3                          1  \n",
       "4                          1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('titanic_all_numeric.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "predictors = df.drop('survived', axis=1).as_matrix()\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols, )\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "target = to_categorical(df.survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_model(input_shape = input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "    model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Testing model with learning rate: 0.000001\n",
      "\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s - loss: 3.9147     \n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s - loss: 3.8727     \n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s - loss: 3.8308     \n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s - loss: 3.7890     \n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s - loss: 3.7475     \n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s - loss: 3.7061     \n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s - loss: 3.6649     \n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s - loss: 3.6239     \n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s - loss: 3.5830     \n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s - loss: 3.5425     \n",
      "\n",
      "\n",
      "Testing model with learning rate: 0.010000\n",
      "\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s - loss: 1.5097     \n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s - loss: 0.7977     \n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s - loss: 0.6467     \n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s - loss: 0.5947     \n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s - loss: 0.6055     \n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s - loss: 0.6073     \n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s - loss: 0.5921     \n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s - loss: 0.5943     \n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s - loss: 0.5741     \n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s - loss: 0.5808     \n",
      "\n",
      "\n",
      "Testing model with learning rate: 1.000000\n",
      "\n",
      "Epoch 1/10\n",
      "891/891 [==============================] - 0s - loss: 9.7694     \n",
      "Epoch 2/10\n",
      "891/891 [==============================] - 0s - loss: 9.9314     \n",
      "Epoch 3/10\n",
      "891/891 [==============================] - 0s - loss: 9.9314     \n",
      "Epoch 4/10\n",
      "891/891 [==============================] - 0s - loss: 9.9314     \n",
      "Epoch 5/10\n",
      "891/891 [==============================] - 0s - loss: 9.9314     \n",
      "Epoch 6/10\n",
      "891/891 [==============================] - 0s - loss: 9.9314     \n",
      "Epoch 7/10\n",
      "891/891 [==============================] - 0s - loss: 9.9314      \n",
      "Epoch 8/10\n",
      "891/891 [==============================] - 0s - loss: 9.9314     \n",
      "Epoch 9/10\n",
      "891/891 [==============================] - 0s - loss: 9.9314     \n",
      "Epoch 10/10\n",
      "891/891 [==============================] - 0s - loss: 9.9314     \n"
     ]
    }
   ],
   "source": [
    "# Import the SGD optimizer\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Create list of learning rates: lr_to_test\n",
    "lr_to_test = [0.000001, 0.01, 1]\n",
    "\n",
    "# Loop over learning rates\n",
    "for lr in lr_to_test:\n",
    "    print('\\n\\nTesting model with learning rate: %f\\n'%lr )\n",
    "    \n",
    "    # Build new model to test, unaffected by previous models\n",
    "    model = get_new_model()\n",
    "    \n",
    "    # Create SGD optimizer with specified learning rate: my_optimizer\n",
    "    my_optimizer = SGD(lr=lr)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=my_optimizer, loss='categorical_crossentropy')\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(predictors, target)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation\n",
    "\n",
    "### Evaluating model accuracy on validation dataset\n",
    "\n",
    "Now it's your turn to monitor model accuracy with a validation data set. A model definition has been provided as model. Your job is to add the code to compile it and then fit it. You'll check the validation score in each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/10\n",
      "623/623 [==============================] - 0s - loss: 0.8564 - acc: 0.6003 - val_loss: 0.5331 - val_acc: 0.7164\n",
      "Epoch 2/10\n",
      "623/623 [==============================] - 0s - loss: 0.6486 - acc: 0.6565 - val_loss: 0.6239 - val_acc: 0.6791\n",
      "Epoch 3/10\n",
      "623/623 [==============================] - 0s - loss: 0.6093 - acc: 0.6838 - val_loss: 0.5264 - val_acc: 0.7687\n",
      "Epoch 4/10\n",
      "623/623 [==============================] - 0s - loss: 0.6500 - acc: 0.6709 - val_loss: 0.5276 - val_acc: 0.7313\n",
      "Epoch 5/10\n",
      "623/623 [==============================] - 0s - loss: 0.6370 - acc: 0.6838 - val_loss: 0.5003 - val_acc: 0.7463\n",
      "Epoch 6/10\n",
      "623/623 [==============================] - 0s - loss: 0.6026 - acc: 0.6918 - val_loss: 0.4932 - val_acc: 0.7612\n",
      "Epoch 7/10\n",
      "623/623 [==============================] - 0s - loss: 0.6503 - acc: 0.6693 - val_loss: 0.5109 - val_acc: 0.7724\n",
      "Epoch 8/10\n",
      "623/623 [==============================] - 0s - loss: 0.5714 - acc: 0.7030 - val_loss: 0.6922 - val_acc: 0.7127\n",
      "Epoch 9/10\n",
      "623/623 [==============================] - 0s - loss: 0.5832 - acc: 0.7352 - val_loss: 0.5950 - val_acc: 0.7463\n",
      "Epoch 10/10\n",
      "623/623 [==============================] - 0s - loss: 0.5542 - acc: 0.7127 - val_loss: 0.4858 - val_acc: 0.7985\n"
     ]
    }
   ],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "hist = model.fit(predictors, target, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping: Optimizing the optimization\n",
    "\n",
    "Now that you know how to monitor your model performance throughout optimization, you can use early stopping to stop optimization when it isn't helping any more. Since the optimization stops automatically when it isn't helping, you can also set a high value for epochs in your call to .fit(), as Dan showed in the video.\n",
    "\n",
    "The model you'll optimize has been specified as model. As before, the data is pre-loaded as predictors and target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 623 samples, validate on 268 samples\n",
      "Epoch 1/30\n",
      "623/623 [==============================] - 0s - loss: 1.1151 - acc: 0.5923 - val_loss: 0.5920 - val_acc: 0.7388\n",
      "Epoch 2/30\n",
      "623/623 [==============================] - 0s - loss: 0.7319 - acc: 0.6388 - val_loss: 0.6973 - val_acc: 0.6418\n",
      "Epoch 3/30\n",
      "623/623 [==============================] - 0s - loss: 0.6408 - acc: 0.6806 - val_loss: 0.6384 - val_acc: 0.6866\n",
      "Epoch 4/30\n",
      "623/623 [==============================] - 0s - loss: 0.6498 - acc: 0.6709 - val_loss: 0.5891 - val_acc: 0.6940\n",
      "Epoch 5/30\n",
      "623/623 [==============================] - 0s - loss: 0.6261 - acc: 0.6806 - val_loss: 0.5220 - val_acc: 0.7537\n",
      "Epoch 6/30\n",
      "623/623 [==============================] - 0s - loss: 0.6111 - acc: 0.6950 - val_loss: 0.5314 - val_acc: 0.7239\n",
      "Epoch 7/30\n",
      "623/623 [==============================] - 0s - loss: 0.6535 - acc: 0.6870 - val_loss: 0.7313 - val_acc: 0.6455\n",
      "Epoch 8/30\n",
      "623/623 [==============================] - 0s - loss: 0.6613 - acc: 0.6902 - val_loss: 0.5534 - val_acc: 0.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1261dfda0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import EarlyStopping\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = predictors.shape[1]\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "# Specify the model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape = input_shape))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(predictors, target, validation_split=0.3, epochs=30, callbacks=[early_stopping_monitor])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimenting with wider networks\n",
    "\n",
    "Now you know everything you need to begin experimenting with different models!\n",
    "\n",
    "A model called model_1 has been pre-loaded. You can see a summary of this model printed in the IPython Shell. This is a relatively small network, with only 10 units in each hidden layer.\n",
    "\n",
    "In this exercise you'll create a new model called model_2 which is similar to model_1, except it has 100 units in each hidden layer.\n",
    "\n",
    "After you create model_2, both models will be fitted, and a graph showing both models loss score at each epoch will be shown. We added the argument verbose=False in the fitting commands to print out fewer updates, since you will look at these graphically instead of as text.\n",
    "\n",
    "Because you are fitting two models, it will take a moment to see the outputs after you hit run, so be patient.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127001c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define early_stopping_monitor\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "\n",
    "# Create model_1\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(10, activation='relu', input_shape=input_shape))\n",
    "model_1.add(Dense(10, activation='relu'))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first and second layers\n",
    "model_2.add(Dense(100, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(100, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model_1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model_2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=15, validation_split=0.2, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "\n",
    "# Create the plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_16 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 242\n",
      "Trainable params: 242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 100)               1100      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 2)                 202       \n",
      "=================================================================\n",
      "Total params: 11,402\n",
      "Trainable params: 11,402\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding layers to a network\n",
    "\n",
    "You've seen how to experiment with wider networks. In this exercise, you'll try a deeper network (more hidden layers).\n",
    "\n",
    "Once again, you have a baseline model called model_1 as a starting point. It has 1 hidden layer, with 50 units. You can see a summary of that model's structure printed out. You will create a similar network with 3 hidden layers (still keeping 50 units in each layer).\n",
    "\n",
    "This will again take a moment to fit both models, so you'll need to wait a few seconds to see the results after you run your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEBGRHkoKIiLSQ0lBRER6KCmIiEiP/w/CR+R66bX1wQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12a42bcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The input shape to use in the first hidden layer\n",
    "input_shape = (n_cols,)\n",
    "\n",
    "\n",
    "# Create model_1\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "model_1.add(Dense(2, activation='softmax'))\n",
    "model_1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create the new model: model_2\n",
    "model_2 = Sequential()\n",
    "\n",
    "# Add the first, second, and third hidden layers\n",
    "model_2.add(Dense(50, activation='relu', input_shape=input_shape))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "model_2.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model_2.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile model_2\n",
    "model_2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit model 1\n",
    "model_1_training = model_1.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Fit model 2\n",
    "model_2_training = model_2.fit(predictors, target, epochs=20, validation_split=0.4, callbacks=[early_stopping_monitor], verbose=False)\n",
    "\n",
    "# Create the plot\n",
    "plt.plot(model_1_training.history['val_loss'], 'r', model_2_training.history['val_loss'], 'b')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Validation score')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 652\n",
      "Trainable params: 652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_24 (Dense)             (None, 50)                550       \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 5,752\n",
      "Trainable params: 5,752\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stepping up to images\n",
    "\n",
    "### Building your own digit recognition model\n",
    "\n",
    "You've reached the final exercise of the course - you now know everything you need to build an accurate model to recognize handwritten digits!\n",
    "\n",
    "We've already done the basic manipulation of the MNIST dataset shown in the video, so you have X and y loaded and ready to model with. Sequential and Dense from keras are also pre-imported.\n",
    "\n",
    "To add an extra challenge, we've loaded only 2500 images, rather than 60000 which you will see in some published results. Deep learning models perform better with more data, however, they also take longer to train, especially when they start becoming more complex.\n",
    "\n",
    "If you have a computer with a CUDA compatible GPU, you can take advantage of it to improve computation time. If you don't have a GPU, no problem! You can set up a deep learning environment in the cloud that can run your models on a GPU. Here is a [blog post](https://www.datacamp.com/community/tutorials/deep-learning-jupyter-aws) by Dan that explains how to do this - check it out after completing this exercise! It is a great next step as you continue your deep learning journey."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mnist = np.genfromtxt('mnist.csv', delimiter=',')\n",
    "X = mnist[:, 1:]\n",
    "y = mnist[:, 0]\n",
    "y = to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1400 samples, validate on 601 samples\n",
      "Epoch 1/10\n",
      "1400/1400 [==============================] - 0s - loss: 13.0592 - acc: 0.1757 - val_loss: 10.1677 - val_acc: 0.3245\n",
      "Epoch 2/10\n",
      "1400/1400 [==============================] - 0s - loss: 8.4489 - acc: 0.4393 - val_loss: 8.2165 - val_acc: 0.4659\n",
      "Epoch 3/10\n",
      "1400/1400 [==============================] - 0s - loss: 6.9395 - acc: 0.5443 - val_loss: 7.2076 - val_acc: 0.5374\n",
      "Epoch 4/10\n",
      "1400/1400 [==============================] - 0s - loss: 6.0690 - acc: 0.6021 - val_loss: 6.4512 - val_acc: 0.5790\n",
      "Epoch 5/10\n",
      "1400/1400 [==============================] - 0s - loss: 5.3999 - acc: 0.6464 - val_loss: 6.1851 - val_acc: 0.5973\n",
      "Epoch 6/10\n",
      "1400/1400 [==============================] - 0s - loss: 5.4924 - acc: 0.6414 - val_loss: 6.0830 - val_acc: 0.6090\n",
      "Epoch 7/10\n",
      "1400/1400 [==============================] - 0s - loss: 5.1234 - acc: 0.6700 - val_loss: 5.7800 - val_acc: 0.6206\n",
      "Epoch 8/10\n",
      "1400/1400 [==============================] - 0s - loss: 4.8461 - acc: 0.6807 - val_loss: 5.6057 - val_acc: 0.6323\n",
      "Epoch 9/10\n",
      "1400/1400 [==============================] - 0s - loss: 4.3100 - acc: 0.7143 - val_loss: 4.5146 - val_acc: 0.6872\n",
      "Epoch 10/10\n",
      "1400/1400 [==============================] - 0s - loss: 3.7228 - acc: 0.7536 - val_loss: 4.2662 - val_acc: 0.7205\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12acb0c88>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first hidden layer\n",
    "model.add(Dense(50, activation='relu', input_shape=(784, )))\n",
    "\n",
    "# Add the second hidden layer\n",
    "model.add(Dense(50, activation='relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X, y, validation_split=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
